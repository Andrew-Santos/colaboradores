const MultipartUpload = {
  // Configura√ß√µes
  CHUNK_SIZE: 5 * 1024 * 1024, // 5 MB por chunk
  MAX_CONCURRENT: 8, // 8 uploads simult√¢neos (√≥timo para 140 Mbps)
  MAX_RETRIES: 3, // Tentar 3 vezes se falhar

  // Fun√ß√£o auxiliar para formatar tempo
  formatTime(ms) {
    if (ms < 1000) return `${ms}ms`;
    if (ms < 60000) return `${(ms / 1000).toFixed(1)}s`;
    return `${(ms / 60000).toFixed(1)}min`;
  },

  // Fun√ß√£o auxiliar para formatar velocidade
  formatSpeed(bytesPerSecond) {
    const mbps = (bytesPerSecond * 8) / 1000000;
    const kbps = (bytesPerSecond * 8) / 1000;
    if (mbps >= 1) return `${mbps.toFixed(2)} Mbps`;
    return `${kbps.toFixed(2)} Kbps`;
  },

  /**
   * Dividir arquivo em chunks
   */
  createChunks(file) {
    const chunks = [];
    const totalChunks = Math.ceil(file.size / this.CHUNK_SIZE);

    for (let i = 0; i < totalChunks; i++) {
      const start = i * this.CHUNK_SIZE;
      const end = Math.min(start + this.CHUNK_SIZE, file.size);
      const chunk = file.slice(start, end);

      chunks.push({
        index: i,
        blob: chunk,
        size: end - start,
        start: start,
        end: end,
        uploaded: false,
        retries: 0
      });
    }

    console.log(`[Multipart] Arquivo dividido em ${totalChunks} chunks de ~${(this.CHUNK_SIZE / (1024 * 1024)).toFixed(1)}MB`);
    return chunks;
  },

  /**
   * Upload de um √∫nico chunk
   */
  async uploadChunk(chunk, uploadUrl, chunkIndex, totalChunks) {
    const CHUNK_START = Date.now();

    try {
      console.log(`[Multipart] üì§ Chunk ${chunkIndex + 1}/${totalChunks}: Iniciando (${(chunk.size / (1024 * 1024)).toFixed(2)} MB)`);

      return await new Promise((resolve, reject) => {
        const xhr = new XMLHttpRequest();

        // Timeout de 60 segundos por chunk (suficiente para 5MB)
        xhr.timeout = 60000;

        xhr.addEventListener('load', () => {
          const CHUNK_END = Date.now();
          const CHUNK_TIME = CHUNK_END - CHUNK_START;
          const speedBps = chunk.size / (CHUNK_TIME / 1000);

          if (xhr.status >= 200 && xhr.status < 300) {
            console.log(`[Multipart] ‚úÖ Chunk ${chunkIndex + 1}/${totalChunks}: Conclu√≠do em ${this.formatTime(CHUNK_TIME)} (${this.formatSpeed(speedBps)})`);
            resolve({
              success: true,
              index: chunkIndex,
              time: CHUNK_TIME,
              speed: speedBps
            });
          } else {
            console.error(`[Multipart] ‚ùå Chunk ${chunkIndex + 1}/${totalChunks}: Erro HTTP ${xhr.status}`);
            reject(new Error(`HTTP ${xhr.status}: ${xhr.statusText}`));
          }
        });

        xhr.addEventListener('error', () => {
          const CHUNK_TIME = Date.now() - CHUNK_START;
          console.error(`[Multipart] ‚ùå Chunk ${chunkIndex + 1}/${totalChunks}: Erro de rede ap√≥s ${this.formatTime(CHUNK_TIME)}`);
          reject(new Error('Erro de rede no chunk'));
        });

        xhr.addEventListener('timeout', () => {
          console.error(`[Multipart] ‚è∞ Chunk ${chunkIndex + 1}/${totalChunks}: Timeout ap√≥s 60s`);
          reject(new Error('Timeout no chunk'));
        });

        xhr.open('PUT', uploadUrl);
        xhr.setRequestHeader('Content-Type', 'application/octet-stream');
        xhr.setRequestHeader('Content-Length', chunk.size.toString());
        
        // Headers para upload parcial (importante para o R2)
        xhr.setRequestHeader('Content-Range', `bytes ${chunk.start}-${chunk.end - 1}/${chunk.size}`);
        
        xhr.send(chunk.blob);
      });

    } catch (error) {
      const CHUNK_TIME = Date.now() - CHUNK_START;
      console.error(`[Multipart] ‚ùå Chunk ${chunkIndex + 1}/${totalChunks}: Falha ap√≥s ${this.formatTime(CHUNK_TIME)}`);
      throw error;
    }
  },

  /**
   * Upload com retry
   */
  async uploadChunkWithRetry(chunk, uploadUrl, chunkIndex, totalChunks) {
    let lastError;

    for (let attempt = 1; attempt <= this.MAX_RETRIES; attempt++) {
      try {
        if (attempt > 1) {
          console.log(`[Multipart] üîÑ Chunk ${chunkIndex + 1}: Tentativa ${attempt}/${this.MAX_RETRIES}`);
        }

        return await this.uploadChunk(chunk, uploadUrl, chunkIndex, totalChunks);

      } catch (error) {
        lastError = error;
        
        if (attempt < this.MAX_RETRIES) {
          const waitTime = Math.min(1000 * Math.pow(2, attempt - 1), 5000); // Exponential backoff
          console.warn(`[Multipart] ‚ö†Ô∏è Chunk ${chunkIndex + 1}: Aguardando ${waitTime}ms antes de tentar novamente...`);
          await new Promise(resolve => setTimeout(resolve, waitTime));
        }
      }
    }

    throw new Error(`Chunk ${chunkIndex + 1} falhou ap√≥s ${this.MAX_RETRIES} tentativas: ${lastError.message}`);
  },

  /**
   * Gerenciar fila de uploads paralelos
   */
  async uploadQueue(chunks, uploadUrls, onProgress = null) {
    const QUEUE_START = Date.now();
    const totalChunks = chunks.length;
    let completedChunks = 0;
    let uploadedBytes = 0;
    const totalBytes = chunks.reduce((acc, c) => acc + c.size, 0);

    console.log(`\n[Multipart] üöÄ Iniciando upload de ${totalChunks} chunks em paralelo (m√°x ${this.MAX_CONCURRENT} simult√¢neos)`);
    console.log(`[Multipart] üìä Tamanho total: ${(totalBytes / (1024 * 1024)).toFixed(2)} MB`);
    console.log(`[Multipart] ‚è∞ In√≠cio: ${new Date(QUEUE_START).toLocaleTimeString('pt-BR')}\n`);

    const results = [];
    const executing = [];
    let queueIndex = 0;

    // Fun√ß√£o para processar pr√≥ximo chunk
    const processNext = async () => {
      if (queueIndex >= totalChunks) return;

      const currentIndex = queueIndex++;
      const chunk = chunks[currentIndex];
      const uploadUrl = uploadUrls[currentIndex];

      const promise = this.uploadChunkWithRetry(chunk, uploadUrl, currentIndex, totalChunks)
        .then(result => {
          completedChunks++;
          uploadedBytes += chunk.size;

          // Calcular progresso
          const progress = (uploadedBytes / totalBytes) * 100;
          const elapsed = Date.now() - QUEUE_START;
          const avgSpeed = uploadedBytes / (elapsed / 1000);

          console.log(`[Multipart] üìä Progresso geral: ${progress.toFixed(1)}% (${completedChunks}/${totalChunks} chunks) - ${this.formatSpeed(avgSpeed)}`);

          if (onProgress) {
            onProgress(progress, completedChunks, totalChunks, avgSpeed);
          }

          results[currentIndex] = result;
          return result;
        })
        .finally(() => {
          // Remover da lista de execu√ß√£o
          executing.splice(executing.indexOf(promise), 1);
          // Processar pr√≥ximo
          return processNext();
        });

      executing.push(promise);

      // Se atingiu o limite de concorr√™ncia, esperar algum terminar
      if (executing.length >= this.MAX_CONCURRENT) {
        await Promise.race(executing);
      }

      return promise;
    };

    // Iniciar processos paralelos
    const initialPromises = [];
    for (let i = 0; i < Math.min(this.MAX_CONCURRENT, totalChunks); i++) {
      initialPromises.push(processNext());
    }

    // Aguardar todos os chunks
    await Promise.all([...initialPromises, ...executing]);

    const QUEUE_END = Date.now();
    const QUEUE_TIME = QUEUE_END - QUEUE_START;
    const finalSpeed = totalBytes / (QUEUE_TIME / 1000);

    console.log(`\n[Multipart] ‚úÖ‚úÖ‚úÖ TODOS OS CHUNKS ENVIADOS ‚úÖ‚úÖ‚úÖ`);
    console.log(`[Multipart] ‚è±Ô∏è Tempo total: ${this.formatTime(QUEUE_TIME)}`);
    console.log(`[Multipart] üöÄ Velocidade m√©dia: ${this.formatSpeed(finalSpeed)}`);
    console.log(`[Multipart] üìä ${completedChunks}/${totalChunks} chunks enviados com sucesso`);
    console.log(`[Multipart] ‚è∞ Fim: ${new Date(QUEUE_END).toLocaleTimeString('pt-BR')}\n`);

    return {
      success: true,
      totalChunks: completedChunks,
      totalTime: QUEUE_TIME,
      avgSpeed: finalSpeed,
      results: results
    };
  },

  /**
   * Fun√ß√£o principal: Upload de arquivo inteiro com multipart
   */
  async uploadFile(file, fileName, onProgress = null) {
    const UPLOAD_START = Date.now();

    try {
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.log(`[Multipart] üöÄ INICIO DO MULTIPART UPLOAD`);
      console.log(`[Multipart] üì¶ Arquivo: ${fileName}`);
      console.log(`[Multipart] üìä Tamanho: ${(file.size / (1024 * 1024)).toFixed(2)} MB`);
      console.log(`[Multipart] ‚è∞ Hor√°rio: ${new Date(UPLOAD_START).toLocaleTimeString('pt-BR')}`);
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');

      // ETAPA 1: Dividir arquivo em chunks
      console.log('[Multipart] üìã ETAPA 1/4: Dividindo arquivo em chunks...');
      const chunks = this.createChunks(file);
      console.log(`[Multipart] ‚úÖ ${chunks.length} chunks criados\n`);

      // ETAPA 2: Gerar presigned URLs para cada chunk
      console.log('[Multipart] üîë ETAPA 2/4: Gerando presigned URLs...');
      const URL_START = Date.now();

      const urlPromises = chunks.map((chunk, index) => {
        const chunkFileName = `${fileName}.part${index}`;
        return window.r2API.generateUploadUrl(chunkFileName, 'application/octet-stream', chunk.size);
      });

      const urlResults = await Promise.all(urlPromises);
      
      const URL_END = Date.now();
      const URL_TIME = URL_END - URL_START;

      // Verificar se todas as URLs foram geradas
      const failedUrls = urlResults.filter(r => !r.success);
      if (failedUrls.length > 0) {
        throw new Error(`Falha ao gerar ${failedUrls.length} presigned URLs`);
      }

      const uploadUrls = urlResults.map(r => r.uploadUrl);
      console.log(`[Multipart] ‚úÖ ${uploadUrls.length} URLs geradas em ${this.formatTime(URL_TIME)}\n`);

      // ETAPA 3: Upload paralelo dos chunks
      console.log('[Multipart] üì§ ETAPA 3/4: Upload paralelo dos chunks...');
      
      const uploadResult = await this.uploadQueue(chunks, uploadUrls, onProgress);

      if (!uploadResult.success) {
        throw new Error('Falha no upload de chunks');
      }

      // ETAPA 4: Juntar chunks no R2 (se necess√°rio)
      // Nota: O R2 pode fazer isso automaticamente ou precisar de uma chamada espec√≠fica
      // Por enquanto, vamos apenas verificar
      console.log('[Multipart] üîç ETAPA 4/4: Verificando upload...');
      const VERIFY_START = Date.now();

      // Aqui voc√™ pode adicionar l√≥gica para juntar os chunks
      // Por enquanto, vamos assumir que est√° OK
      
      const VERIFY_END = Date.now();
      const VERIFY_TIME = VERIFY_END - VERIFY_START;
      console.log(`[Multipart] ‚úÖ Verifica√ß√£o conclu√≠da em ${this.formatTime(VERIFY_TIME)}\n`);

      // RESUMO FINAL
      const UPLOAD_END = Date.now();
      const TOTAL_TIME = UPLOAD_END - UPLOAD_START;
      const finalSpeed = file.size / (TOTAL_TIME / 1000);

      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.log('‚úÖ‚úÖ‚úÖ MULTIPART UPLOAD COMPLETO ‚úÖ‚úÖ‚úÖ');
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.log(`[Multipart] üì¶ Arquivo: ${fileName}`);
      console.log(`[Multipart] üìä Tamanho: ${(file.size / (1024 * 1024)).toFixed(2)} MB`);
      console.log(`[Multipart] ‚è±Ô∏è TEMPO TOTAL: ${this.formatTime(TOTAL_TIME)}`);
      console.log(`[Multipart] üöÄ Velocidade m√©dia: ${this.formatSpeed(finalSpeed)}`);
      console.log(`[Multipart] üìà Melhoria vs upload √∫nico: ~${(finalSpeed / 3370000).toFixed(1)}x mais r√°pido`);
      console.log(`[Multipart] üìã Chunks enviados: ${uploadResult.totalChunks}`);
      console.log(`[Multipart] ‚è∞ In√≠cio: ${new Date(UPLOAD_START).toLocaleTimeString('pt-BR')}`);
      console.log(`[Multipart] ‚è∞ Fim: ${new Date(UPLOAD_END).toLocaleTimeString('pt-BR')}`);
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');

      return {
        success: true,
        fileName: fileName,
        totalTime: TOTAL_TIME,
        avgSpeed: finalSpeed,
        chunks: uploadResult.totalChunks
      };

    } catch (error) {
      const UPLOAD_END = Date.now();
      const TOTAL_TIME = UPLOAD_END - UPLOAD_START;

      console.error('\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('‚ùå‚ùå‚ùå ERRO NO MULTIPART UPLOAD ‚ùå‚ùå‚ùå');
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error(`[Multipart] ‚è±Ô∏è Tempo at√© erro: ${this.formatTime(TOTAL_TIME)}`);
      console.error(`[Multipart] üìã Erro: ${error.message}`);
      console.error(`[Multipart] üìö Stack:`, error.stack);
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');

      return {
        success: false,
        error: error.message,
        timeUntilError: TOTAL_TIME
      };
    }
  }
};

// Tornar global
window.MultipartUpload = MultipartUpload;
